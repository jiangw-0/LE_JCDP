# Unlearnable Examples Give a False Sense of Security: Piercing through Unexploitable Data with Learnable Examples

This repo contains the official PyTorch implementation of ["Unlearnable Examples Give a False Sense of Security: Piercing through Unexploitable Data with Learnable Examples"](https://arxiv.org/abs/2305.09241) (ACM MM 2023), by Wan Jiang*, [Yunfeng Diao*](http://faculty.hfut.edu.cn/diaoyunfeng/en/index.htm), [He Wang](https://drhewang.com/), JIangxin Sun, Meng Wang and Richang Hong (*co-primary authors).

![overview.png](https://github.com/jiangw-0/LE_JCDP/blob/main/imgs/overview.png)

# Dependencies

Below is the key environment under which the code was developed, not necessarily the minimal requirements:

1.  Python 3.10
2.  Pytorch 2.0.1
3.  Cuda 11.8


# 


# Citation(Bibtex)

If you find this code to be useful for your research, please consider citing.

```
@article{jiang2023unlearnable,
title={Unlearnable Examples Give a False Sense of Security: Piercing through Unexploitable Data with Learnable Examples},
author={Jiang, Wan and Diao, Yunfeng and Wang, He and Sun, Jianxin and Wang, Meng and Hong, Richang},
journal={arXiv preprint arXiv:2305.09241},year={2023}
```

# Contact

Please email <jiangw000@mail.hfut.edu.cn> for further questions.

# Acknowledgment

Diffusion Models Beat GANS on Image Synthesisï¼šhttps://github.com/openai/guided-diffusion
